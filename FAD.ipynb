{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG96d7a4x/jGk+evo5RDs2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cz1544252489/ForMyDeepLearning/blob/main/FAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "读取数据"
      ],
      "metadata": {
        "id": "9gPHUqhviDkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "uRDsLttA0kWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOUAT06Pd9dz"
      },
      "outputs": [],
      "source": [
        "file_name = './sample_data/mnist_train_small.csv'\n",
        "\n",
        "A = []\n",
        "\n",
        "# 打开csv文件\n",
        "with open(file_name, 'r') as file:\n",
        "    # 创建csv阅读器\n",
        "    reader = csv.reader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        # 处理除第一行外的每一行\n",
        "        A.append(row)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(A)\n",
        "p = 28\n",
        "C = 10"
      ],
      "metadata": {
        "id": "No0HhwgJfZ4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "设置数据"
      ],
      "metadata": {
        "id": "azcnfOLqiKTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取第一列到矩阵 v (实际上是一个列表)\n",
        "# 使用列表推导式来收集每行的第一个元素\n",
        "v = [row[0] for row in A]\n",
        "\n",
        "# 提取其他列到矩阵 u\n",
        "# 使用列表推导式来收集每行的其他元素\n",
        "u = [row[1:] for row in A]\n"
      ],
      "metadata": {
        "id": "RKyz3zTDgt-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "把数据分成三组，训练集，验证集和测试集"
      ],
      "metadata": {
        "id": "nn1xPR_1k6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成1到20000的整数数组\n",
        "all_numbers = np.arange(0, 20000)\n",
        "\n",
        "# 从中随机抽取5000个作为D_tr\n",
        "D_tr = np.random.choice(all_numbers, size=5000, replace=False)\n",
        "\n",
        "# 从剩余的中再随机抽取5000个作为D_val\n",
        "remaining_numbers = np.setdiff1d(all_numbers, D_tr)\n",
        "D_val = np.random.choice(remaining_numbers, size=5000, replace=False)\n",
        "\n",
        "# 剩下的即为D_test\n",
        "D_test = np.setdiff1d(remaining_numbers, D_val)\n",
        "\n",
        "u_tr = []\n",
        "v_tr = []\n",
        "for i in D_tr:\n",
        "    u_tr.append(u[i])\n",
        "    v_tr.append(v[i])\n",
        "\n",
        "u_val = []\n",
        "v_val = []\n",
        "for i in D_val:\n",
        "    u_val.append(u[i])\n",
        "    v_val.append(v[i])\n",
        "\n",
        "u_test = []\n",
        "v_test = []\n",
        "for i in D_test:\n",
        "    u_test.append(u[i])\n",
        "    v_test.append(v[i])\n",
        "\n",
        "u_tr = np.array(np.transpose(u_tr), dtype=np.int32)\n",
        "v_tr = np.array(np.transpose(v_tr), dtype=np.int32)\n",
        "u_val = np.array(np.transpose(u_val), dtype=np.int32)\n",
        "v_val = np.array(np.transpose(v_val), dtype=np.int32)\n",
        "u_test = np.array(np.transpose(u_test), dtype=np.int32)\n",
        "v_test = np.array(np.transpose(v_test), dtype=np.int32)"
      ],
      "metadata": {
        "id": "jhQLTRF2lAs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "生成初始超参数"
      ],
      "metadata": {
        "id": "G52bqglCkjwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.random.rand(p**2,C)\n",
        "x = np.random.rand(N)"
      ],
      "metadata": {
        "id": "ChLFTkaRhkNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "开始定义上下层目标函数"
      ],
      "metadata": {
        "id": "0x-ginf3kr-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(logits):\n",
        "    exp_logits = np.exp(logits - np.max(logits))  # 防止数值溢出\n",
        "    softmax_values = exp_logits / np.sum(exp_logits, axis=0)\n",
        "    return softmax_values\n",
        "\n",
        "\n",
        "def lower_obj(x,y,u_tr,v_tr):\n",
        "  y_trans = np.transpose(y)\n",
        "  z = np.dot(y_trans,u_tr)\n",
        "  v_hat = softmax(z)\n",
        "  loss = -np.sum(np.multiply(v_tr,np.log(v_hat)))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "UMmwMNMOkwOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  y_trans = np.transpose(y)\n",
        "  z = np.dot(y_trans,u_tr)\n",
        "  z = torch.tensor(np.transpose(z), dtype=torch.long)\n",
        "  v_tr = torch.tensor(v_tr, dtype=torch.long)\n",
        "# 使用 torch.nn.functional.cross_entropy 计算交叉熵损失\n",
        "  loss = F.cross_entropy(z, v_tr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "J-I7PBeao9JG",
        "outputId": "463e47f4-d255-4c9e-f8b0-8807f69372c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-b0cbe63c9fc0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mv_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 使用 torch.nn.functional.cross_entropy 计算交叉熵损失\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3,4])\n",
        "b = np.array([[1],[2],[3],[4]])\n",
        "c = np.array([[1,2,3,4],[1,2,3,4]])\n",
        "print(softmax(a))\n",
        "print(softmax(b))\n",
        "print(softmax(c))"
      ],
      "metadata": {
        "id": "MxcbGeBBqDsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = np.log(softmax(v_tr))\n",
        "print(len(d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7KdHwcDvOKa",
        "outputId": "2449bbb7-db6d-4b4f-a26a-345a529d8d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n"
          ]
        }
      ]
    }
  ]
}